{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 3: Summary\n",
    "\n",
    "Attempted to run for 50 epochs, batch size 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dill in c:\\users\\mariel\\anaconda3\\lib\\site-packages (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport shutil\\nimport os\\n\\nsource = \\'./food-101/test/ramen\\'\\ndest = \\'./food-101/valid/ramen\\'\\n\\nfiles = os.listdir(source)\\n\\ni = 0\\nfor f in files:\\n    if i < 175:\\n        file= os.path.join(source, f)\\n        shutil.move(file,dest)\\n        print(\"adding img \", i)\\n    i+=1\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "source = './food-101/test/ramen'\n",
    "dest = './food-101/valid/ramen'\n",
    "\n",
    "files = os.listdir(source)\n",
    "\n",
    "i = 0\n",
    "for f in files:\n",
    "    if i < 175:\n",
    "        file= os.path.join(source, f)\n",
    "        shutil.move(file,dest)\n",
    "        print(\"adding img \", i)\n",
    "    i+=1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Loading Data\n",
    "\n",
    "For loading the data, I first used the train/test split that was provided with our dataset.  This gave us 750 images in train and 250 in test PER class.  Then, I split the test set into test & validation.  I moved 175 images to the validation set, thus we are left with 75 images in test.\n",
    "\n",
    "For image preprocessing, I first resize each image to our IMG_SIZE constant, currently set to 224 pixels.  I then recolor the image to RGB.  I also assign the labels to the images and shuffle the dataset.\n",
    "\n",
    "\n",
    "After loading the data, the shape of X (features) will be (-1 {this means any number of features}, IMG_SIZE, IMG_SIZE, 3 {number of channels - RGB}), and the shape of y (labels) will be (-1, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import shutil\n",
    "import stat\n",
    "\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 5\n",
    "noodle_classes = ['pad_thai','pho','ramen','spaghetti_bolognese','spaghetti_carbonara']\n",
    "\n",
    "# these are the main variables we tested and documented\n",
    "EPOCHS = 50\n",
    "BATCH_SZ = 32\n",
    "LEARN_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create the datasets (train, test, and valid)\n",
    "# preprocesses the images (resize/recolor), assigns labels, and shuffles the dataset\n",
    "root_dir = 'food-101/images/'\n",
    "\n",
    "def create_data(root, _name):\n",
    "    data_set = []\n",
    "\n",
    "    for noodle_class in noodle_classes:\n",
    "        path = os.path.join(root, noodle_class)\n",
    "        label = noodle_classes.index(noodle_class) # assign an integer label to the image based on our noodle_classes array\n",
    "        print(noodle_class,label)\n",
    "\n",
    "        for img in os.listdir(path): # iterates through each image in the noodle folder\n",
    "                if img.startswith('.'):\n",
    "                    continue\n",
    "                # each image is a 2D array of RGB value\n",
    "                try:\n",
    "                    img_arr = cv2.imread(os.path.join(path,img)) \n",
    "                    img_to_rgb = img_arr[:,:,::-1] # recolor\n",
    "                    new_img = cv2.resize(img_to_rgb,(IMG_SIZE,IMG_SIZE)) #resize\n",
    "                    data_set.append([new_img,label]) # store image and label together in dataset so we can shuffle without images getting mislabeled\n",
    "                except Exception as e: # catch bad images\n",
    "                    print(\"create exception: \",e)\n",
    "        \n",
    "    # randomize\n",
    "    random.shuffle(data_set)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for features, label in data_set:\n",
    "        X.append(features) # 2D array of RGB values representing features\n",
    "        y.append(label) # integer representing class/label\n",
    "\n",
    "    # reshape X and y\n",
    "    X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    print('X', X.shape)\n",
    "    print('y', y.shape)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_thai 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'food-101/train\\\\pad_thai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6cae02af1e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# load data in train, test, and valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'food-101/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'food-101/test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'food-101/valid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-10c11e039e74>\u001b[0m in \u001b[0;36mcreate_data\u001b[0;34m(root, _name)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoodle_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# iterates through each image in the noodle folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'food-101/train\\\\pad_thai'"
     ]
    }
   ],
   "source": [
    "# load data in train, test, and valid\n",
    "\n",
    "X_train, y_train = create_data('food-101/train', \"train\")\n",
    "X_test, y_test = create_data('food-101/test', \"test\")\n",
    "X_valid, y_valid = create_data('food-101/valid', \"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization and Augmentation\n",
    "Here I am normalizing the data to scale our input training vectors. This will help improve accuracy and increase training speed.\n",
    "\n",
    "Currently, I am attempting to implement image augmentation to improve accuracy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "# X_train = X_train/255.0\n",
    "# X_test = X_test/255.0\n",
    "\n",
    "#print('X train before normalize',X_train[1])\n",
    "print('y train before normal',y_train)\n",
    "# input('wait1')\n",
    "\n",
    "# L2-normalizes the given array, i.e., it makes the sum of squares of each element of the array to be equal to one\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "\n",
    "#print('X train after normal',X_train[1])\n",
    "print('y train after normal',y_train)\n",
    "\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "X_valid = tf.keras.utils.normalize(X_valid, axis=1)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image augmentation - for better performance\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = True,\n",
    "    featurewise_std_normalization = True,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet 16\n",
    "This is the 16-layer VGGNet architecture which consists of twelve convolutional layers, some followed by max pooling layers, four fully-connected layers, and lastly a softmax classifier.\n",
    "\n",
    "The \"VGG-blocks\" is what stood out about this paper.  These blocks contain the convolutional layers whcich use small 3x3 filters followed by a max pooling layer with size 2x2 and stride 2.\n",
    "\n",
    "See below for a chart depicting the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# creating the actual model using the VGGNet16 architecture\n",
    "\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3) # 224x224x3 RGB image\n",
    "\n",
    "#Instantiate an empty model\n",
    "model = Sequential([\n",
    "Conv2D(64, (3, 3), input_shape=input_shape, padding='same', activation='relu'), # first two convolutional layers\n",
    "Conv2D(64, (3, 3), activation='relu', padding='same'), # 64 filters | 224x224x64\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), # image dim -> 112x112x64\n",
    "Conv2D(128, (3, 3), activation='relu', padding='same'), # 128 filters, size 3x3, stride 1\n",
    "Conv2D(128, (3, 3), activation='relu', padding='same',), \n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), # image dim -> 56x56x128\n",
    "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), # 28x28x256\n",
    "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), # 14x14x512\n",
    "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), # 7x7x512\n",
    "Flatten(), # flatten through fully connected layer with 25088 filters size 1x1\n",
    "Dense(4096, activation='relu'), # 2 more fully connected layers\n",
    "Dense(4096, activation='relu'),\n",
    "Dense(5, activation='softmax') # softmax output layer, 5 possible values/classes\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, show_shapes=True, to_file='vgg_block.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling model and training\n",
    "\n",
    "opt = optimizers.SGD(lr=LEARN_RATE, momentum=.9) # momentum help accelerate gradient vectors in the right directions\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "'''\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='SGD', metrics=['accuracy'])\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "'''\n",
    "# fitting model without image augmentation\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=BATCH_SZ, \n",
    "          epochs=EPOCHS,     \n",
    "          validation_data=(X_valid, y_valid))\n",
    "'''\n",
    "\n",
    "# fitting model with image augmentation\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=BATCH_SZ),\n",
    "                    steps_per_epoch=len(X_train) / 64,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate model on test data\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "# verbose indiciator to display training progress info\n",
    "# 1 (true) (default) | 0 (false)\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Image Augmentation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.6084</td>\n",
       "      <td>0.4133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.6089</td>\n",
       "      <td>0.2987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epochs  Batch Size  Learning Rate  Test Loss  Test Accuracy\n",
       "0      30          32         0.0001     1.6084         0.4133\n",
       "1      40          64         0.0001     1.6089         0.2987"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keeping track of overall results\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Before Image Augmentation:\")\n",
    "data = [[30, 32, 0.0001, 1.6084, 0.4133],\n",
    "        [40, 64, 0.0001, 1.6089, 0.2987]]\n",
    "pd.DataFrame(data, columns=[\"Epochs\", \"Batch Size\", \"Learning Rate\", \"Test Loss\", \"Test Accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
