{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 7: Summary\n",
    "\n",
    "In this iteration, I was trying to get the test accuracy and loss using the configurations from the previous iteration, however I lost Internet connection and the training ended at epoch 29/30.  It ended with a val acc of 0.68 and a val loss of 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source = './food-101/test/ramen'\n",
    "dest = './food-101/valid/ramen'\n",
    "\n",
    "files = os.listdir(source)\n",
    "\n",
    "i = 0\n",
    "for f in files:\n",
    "    if i < 175:\n",
    "        file= os.path.join(source, f)\n",
    "        shutil.move(file,dest)\n",
    "        print(\"adding img \", i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Loading Data\n",
    "\n",
    "For loading the data, I first used the train/test split that was provided with our dataset.  This gave us 750 images in train and 250 in test PER CLASS.  Then, I split the test set into test & validation.  I moved 175 images to the validation set, thus we are left with 75 images in test.\n",
    "\n",
    "For image preprocessing, I first resize each image to our IMG_SIZE constant, currently set to 224 pixels.  I then recolor the image to RGB.  I also assign the labels to the images and shuffle the dataset.\n",
    "\n",
    "\n",
    "After loading the data, the shape of X (features) will be (-1 {this means any number of features}, IMG_SIZE, IMG_SIZE, 3 {number of channels - RGB}), and the shape of y (labels) will be (-1, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import shutil\n",
    "import stat\n",
    "\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 5\n",
    "noodle_classes = ['pad_thai','pho','ramen','spaghetti_bolognese','spaghetti_carbonara']\n",
    "\n",
    "# these are the main variables we tested and documented\n",
    "EPOCHS = 30\n",
    "BATCH_SZ = 64\n",
    "LEARN_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to create the datasets (train, test, and valid)\n",
    "# preprocesses the images (resize/recolor), assigns labels, and shuffles the dataset\n",
    "root_dir = 'food-101/images/'\n",
    "\n",
    "def create_data(root, _name):\n",
    "    data_set = []\n",
    "\n",
    "    for noodle_class in noodle_classes:\n",
    "        path = os.path.join(root, noodle_class)\n",
    "        label = noodle_classes.index(noodle_class) # assign an integer label to the image based on our noodle_classes array\n",
    "        print(noodle_class,label)\n",
    "\n",
    "        for img in os.listdir(path): # iterates through each image in the noodle folder\n",
    "                if img.startswith('.'):\n",
    "                    continue\n",
    "                # each image is a 2D array of RGB value\n",
    "                try:\n",
    "                    img_arr = cv2.imread(os.path.join(path,img)) \n",
    "                    img_to_rgb = img_arr[:,:,::-1] # recolor\n",
    "                    new_img = cv2.resize(img_to_rgb,(IMG_SIZE,IMG_SIZE)) #resize\n",
    "                    data_set.append([new_img,label]) # store image and label together in dataset so we can shuffle without images getting mislabeled\n",
    "                except Exception as e: # catch bad images\n",
    "                    print(\"create exception: \",e)\n",
    "        \n",
    "    # randomize\n",
    "    random.shuffle(data_set)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for features, label in data_set:\n",
    "        X.append(features) # 2D array of RGB values representing features\n",
    "        y.append(label) # integer representing class/label\n",
    "\n",
    "    # reshape X and y\n",
    "    X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    print('X', X.shape)\n",
    "    print('y', y.shape)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_thai 0\n",
      "pho 1\n",
      "ramen 2\n",
      "spaghetti_bolognese 3\n",
      "spaghetti_carbonara 4\n",
      "X (3750, 224, 224, 3)\n",
      "y (3750, 1)\n",
      "pad_thai 0\n",
      "pho 1\n",
      "ramen 2\n",
      "spaghetti_bolognese 3\n",
      "spaghetti_carbonara 4\n",
      "X (375, 224, 224, 3)\n",
      "y (375, 1)\n",
      "pad_thai 0\n",
      "pho 1\n",
      "ramen 2\n",
      "spaghetti_bolognese 3\n",
      "spaghetti_carbonara 4\n",
      "X (875, 224, 224, 3)\n",
      "y (875, 1)\n"
     ]
    }
   ],
   "source": [
    "# load data in train, test, and valid\n",
    "\n",
    "X_train, y_train = create_data('food-101/train', \"train\")\n",
    "X_test, y_test = create_data('food-101/test', \"test\")\n",
    "X_valid, y_valid = create_data('food-101/valid', \"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization and Augmentation\n",
    "Here I am normalizing the data to scale our input training vectors. This will help improve accuracy and increase training speed.\n",
    "\n",
    "Currently, I am attempting to implement image augmentation to improve accuracy as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train before normal [[1]\n",
      " [1]\n",
      " [4]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "y train after normal [[0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "(3750, 5)\n"
     ]
    }
   ],
   "source": [
    "# normalize data\n",
    "# X_train = X_train/255.0\n",
    "# X_test = X_test/255.0\n",
    "\n",
    "#print('X train before normalize',X_train[1])\n",
    "print('y train before normal',y_train)\n",
    "# input('wait1')\n",
    "\n",
    "# L2-normalizes the given array, i.e., it makes the sum of squares of each element of the array to be equal to one\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "\n",
    "#print('X train after normal',X_train[1])\n",
    "print('y train after normal',y_train)\n",
    "\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "X_valid = tf.keras.utils.normalize(X_valid, axis=1)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, NUM_CLASSES)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "print('y train after normal',y_train)\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# image augmentation - for better performance\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 90,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    brightness_range=[0.2,1.0],\n",
    "    zoom_range=[0.5,1.0]\n",
    "    #preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "datagener = datagen.flow(X_train, y_train, batch_size = BATCH_SZ, shuffle=True)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# image augmentation - for better performance\n",
    "vdatagen = ImageDataGenerator(\n",
    "    rotation_range = 90,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    brightness_range=[0.2,1.0],\n",
    "    zoom_range=[0.5,1.0]\n",
    "    #preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "vdatagener = vdatagen.flow(X_valid, y_valid, batch_size = BATCH_SZ, shuffle=True)\n",
    "vdatagen.fit(X_valid)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), X_test.std()))\n",
    "\n",
    "# generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center = True,\n",
    "                            featurewise_std_normalization = True)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "train_iterator = datagen.flow(X_train, y_train, batch_size=BATCH_SZ)\n",
    "test_iterator = datagen.flow(X_test, y_test, batch_size=BATCH_SZ)\n",
    "valid_iterator = datagen.flow(X_valid, y_valid, batch_size=BATCH_SZ)\n",
    "\n",
    "'''\n",
    "# show the effect on a single batch of samples\n",
    "iterator = datagen.flow(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=64)\n",
    "\n",
    "# get a batch\n",
    "X_batch, y_batch = iterator.next()\n",
    "#pixel stats in the batch\n",
    "print(X_batch.shape, X_batch.mean(), X_batch.std())\n",
    "\n",
    "# show effect on entire dataset\n",
    "iterator = datagen.flow(X_train,\n",
    "                        y_train,\n",
    "                        batch_size = len(X_train),\n",
    "                        shuffle = False)\n",
    "\n",
    "# get a batch\n",
    "X_batch, y_batch = iterator.next()\n",
    "# pixel stats in the batch\n",
    "print(X_batch.shape, X_batch.mean(), X_batch.std())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet \n",
    "Simplified to 10 layers.  Added Glorot Normal weight initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              205521920 \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 208,312,133\n",
      "Trainable params: 208,312,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization, LeakyReLU\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# creating the actual model using the VGGNet16 architecture\n",
    "\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3) # 224x224x3 RGB image\n",
    "\n",
    "#Instantiate an empty model\n",
    "model = Sequential([\n",
    "Conv2D(64, (3, 3), input_shape=input_shape, kernel_initializer='glorot_normal', bias_initializer='zeros', padding='same'), # first two convolutional layers\n",
    "LeakyReLU(alpha=0.01),\n",
    "Conv2D(64, (3, 3), padding='same'),\n",
    "LeakyReLU(alpha=0.01),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "Conv2D(128, (3, 3), padding='same'), \n",
    "LeakyReLU(alpha=0.01),\n",
    "Conv2D(128, (3, 3), padding='same',), \n",
    "LeakyReLU(alpha=0.01),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "Conv2D(256, (3, 3), padding='same',),\n",
    "LeakyReLU(alpha=0.01),\n",
    "Conv2D(256, (3, 3), padding='same',),\n",
    "LeakyReLU(alpha=0.01),\n",
    "Conv2D(256, (3, 3), padding='same',),\n",
    "LeakyReLU(alpha=0.01),\n",
    "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), \n",
    "Flatten(), \n",
    "Dense(1024), # fully connected layers\n",
    "LeakyReLU(alpha=0.01),\n",
    "Dense(1024),\n",
    "LeakyReLU(alpha=0.01),\n",
    "Dense(5, activation='softmax') # softmax output layer, 5 possible values/classes\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#plot_model(model, show_shapes=True, to_file='vgg_block.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750, 224, 224, 3)\n",
      "(3750, 5)\n",
      "Epoch 1/30\n",
      "58/58 [==============================] - 1098s 19s/step - loss: 37.7237 - accuracy: 0.2062 - val_loss: 1.6025 - val_accuracy: 0.2114\n",
      "Epoch 2/30\n",
      "58/58 [==============================] - 1084s 19s/step - loss: 1.4994 - accuracy: 0.3288 - val_loss: 1.4364 - val_accuracy: 0.4446\n",
      "Epoch 3/30\n",
      "58/58 [==============================] - 1079s 19s/step - loss: 1.4050 - accuracy: 0.4075 - val_loss: 1.3265 - val_accuracy: 0.4663\n",
      "Epoch 4/30\n",
      "58/58 [==============================] - 1036s 18s/step - loss: 1.3034 - accuracy: 0.4666 - val_loss: 1.2716 - val_accuracy: 0.5017\n",
      "Epoch 5/30\n",
      "58/58 [==============================] - 1024s 18s/step - loss: 1.3079 - accuracy: 0.4498 - val_loss: 1.2057 - val_accuracy: 0.5109\n",
      "Epoch 6/30\n",
      "58/58 [==============================] - 1018s 18s/step - loss: 1.2481 - accuracy: 0.5022 - val_loss: 1.2627 - val_accuracy: 0.5051\n",
      "Epoch 7/30\n",
      "58/58 [==============================] - 1047s 18s/step - loss: 1.1895 - accuracy: 0.5209 - val_loss: 0.7465 - val_accuracy: 0.5806\n",
      "Epoch 8/30\n",
      "58/58 [==============================] - 1058s 18s/step - loss: 1.2013 - accuracy: 0.5062 - val_loss: 1.0080 - val_accuracy: 0.5474\n",
      "Epoch 9/30\n",
      "58/58 [==============================] - 1059s 18s/step - loss: 1.1300 - accuracy: 0.5515 - val_loss: 0.8131 - val_accuracy: 0.5646\n",
      "Epoch 10/30\n",
      "58/58 [==============================] - 1060s 18s/step - loss: 1.0694 - accuracy: 0.5762 - val_loss: 0.9574 - val_accuracy: 0.6171\n",
      "Epoch 11/30\n",
      "58/58 [==============================] - 1042s 18s/step - loss: 1.0478 - accuracy: 0.5797 - val_loss: 0.6429 - val_accuracy: 0.6366\n",
      "Epoch 12/30\n",
      "58/58 [==============================] - 1051s 18s/step - loss: 1.0437 - accuracy: 0.5754 - val_loss: 1.1105 - val_accuracy: 0.6297\n",
      "Epoch 13/30\n",
      "58/58 [==============================] - 1045s 18s/step - loss: 0.9990 - accuracy: 0.6134 - val_loss: 0.8609 - val_accuracy: 0.6503\n",
      "Epoch 14/30\n",
      "58/58 [==============================] - 1053s 18s/step - loss: 1.0236 - accuracy: 0.5917 - val_loss: 1.1106 - val_accuracy: 0.6331\n",
      "Epoch 15/30\n",
      "58/58 [==============================] - 1062s 18s/step - loss: 0.9994 - accuracy: 0.5974 - val_loss: 1.0969 - val_accuracy: 0.6206\n",
      "Epoch 16/30\n",
      "58/58 [==============================] - 1055s 18s/step - loss: 0.9278 - accuracy: 0.6427 - val_loss: 0.7600 - val_accuracy: 0.6560\n",
      "Epoch 17/30\n",
      "58/58 [==============================] - 1063s 18s/step - loss: 0.9724 - accuracy: 0.6253 - val_loss: 1.0261 - val_accuracy: 0.6583\n",
      "Epoch 18/30\n",
      "58/58 [==============================] - 1011s 17s/step - loss: 0.9442 - accuracy: 0.6311 - val_loss: 0.9239 - val_accuracy: 0.6903\n",
      "Epoch 19/30\n",
      "58/58 [==============================] - 1038s 18s/step - loss: 0.8790 - accuracy: 0.6568 - val_loss: 0.7494 - val_accuracy: 0.6594\n",
      "Epoch 20/30\n",
      "58/58 [==============================] - 1046s 18s/step - loss: 0.8864 - accuracy: 0.6604 - val_loss: 0.8049 - val_accuracy: 0.6971\n",
      "Epoch 21/30\n",
      "58/58 [==============================] - 1032s 18s/step - loss: 0.8541 - accuracy: 0.6791 - val_loss: 1.1156 - val_accuracy: 0.6949\n",
      "Epoch 22/30\n",
      "58/58 [==============================] - 1024s 18s/step - loss: 0.8719 - accuracy: 0.6609 - val_loss: 0.8928 - val_accuracy: 0.6457\n",
      "Epoch 23/30\n",
      "58/58 [==============================] - 1074s 19s/step - loss: 0.8772 - accuracy: 0.6587 - val_loss: 0.8582 - val_accuracy: 0.6423\n",
      "Epoch 24/30\n",
      "58/58 [==============================] - 1055s 18s/step - loss: 0.8615 - accuracy: 0.6734 - val_loss: 0.6884 - val_accuracy: 0.6960\n",
      "Epoch 25/30\n",
      "58/58 [==============================] - 1051s 18s/step - loss: 0.8385 - accuracy: 0.6766 - val_loss: 0.7919 - val_accuracy: 0.7131\n",
      "Epoch 26/30\n",
      "58/58 [==============================] - 1022s 18s/step - loss: 0.8449 - accuracy: 0.6699 - val_loss: 0.8419 - val_accuracy: 0.7223\n",
      "Epoch 27/30\n",
      "58/58 [==============================] - 1053s 18s/step - loss: 0.8194 - accuracy: 0.6983 - val_loss: 0.6127 - val_accuracy: 0.7291\n",
      "Epoch 28/30\n",
      "58/58 [==============================] - 1079s 19s/step - loss: 0.8110 - accuracy: 0.6913 - val_loss: 0.7954 - val_accuracy: 0.7143\n",
      "Epoch 29/30\n",
      "58/58 [==============================] - 1094s 19s/step - loss: 0.8182 - accuracy: 0.6732 - val_loss: 0.7550 - val_accuracy: 0.6777\n",
      "Epoch 30/30\n",
      "47/58 [=======================>......] - ETA: 3:05 - loss: 0.7933 - accuracy: 0.6928"
     ]
    }
   ],
   "source": [
    "# compiling model and training\n",
    "\n",
    "opt = optimizers.SGD(lr=LEARN_RATE, momentum=.9) # momentum help accelerate gradient vectors in the right directions\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "'''\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='SGD', metrics=['accuracy'])\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "'''\n",
    "# fitting model without image augmentation\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=BATCH_SZ, \n",
    "          epochs=EPOCHS,     \n",
    "          validation_data=(X_valid, y_valid))\n",
    "'''\n",
    "\n",
    "# fitting model with image augmentation\n",
    "model.fit_generator(datagener,\n",
    "                    steps_per_epoch=X_train.shape[0] // BATCH_SZ,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=vdatagener,\n",
    "                    shuffle=True)\n",
    "\n",
    "'''\n",
    "# fitting model with image standardization using ImageDataGenerator\n",
    "model.fit_generator(train_iterator,\n",
    "                    steps_per_epoch=len(train_iterator),\n",
    "                    epochs=EPOCHS)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate model on test data\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "# verbose indiciator to display training progress info\n",
    "# 1 (true) (default) | 0 (false)\n",
    "#scores = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
