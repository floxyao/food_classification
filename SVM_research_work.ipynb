{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install these library on TERMINAL if you haven't install\n",
    "\n",
    "pip install matplotlib tensorflow opency-python scikit-learn scikit-image pillow pandas\n",
    "\n",
    "\n",
    "For Window Linux Subsystem user:\n",
    "1. Display plot from matplotlib require Xming Server running.\n",
    "2. Download (Xming)[https://sourceforge.net/projects/xming/]\n",
    "3. Update .bashrc\n",
    "    vim ~/.bashrc\n",
    "4. Append at the end of the file\n",
    "    export DISPLAY=:0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for tkinter\n",
    "if os.environ.get('DISPLAY','') == '':\n",
    "    print('no display found. Using non-interactive Agg backend')\n",
    "    mpl.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "# parent_dir and model_dir should be change according \n",
    "# the dataset location and location of save models according to users \n",
    "parent_dir = \"/mnt/c/Users/nhmin/Downloads/food-101/\"\n",
    "bin_n = 16 # Number of bin\n",
    "project_dir = os.getcwd()\n",
    "model_dir = \"/mnt/c/Users/nhmin/Downloads/\"\n",
    "# List of class take from the dataset\n",
    "class_label = [\"pad_thai\", \"pho\", \"ramen\", \"spaghetti_bolognese\", \"spaghetti_carbonara\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_image()` taken in image path and return numpy 384x384 array of the image.\n",
    "`load_json(path)` return a dictionary of classes as key and list of image directories as value. This is load from **train.json** and **test.json** in the **meta** folder from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class take from the dataset\n",
    "class_label = [\"pad_thai\", \"pho\", \"ramen\", \"spaghetti_bolognese\", \"spaghetti_carbonara\"]\n",
    "\n",
    "def get_image(path):\n",
    "    # image size = 384x384\n",
    "    img = Image.open(path + \".jpg\")\n",
    "    resized_image = img.resize((384,384), Image.ANTIALIAS)\n",
    "    return np.array(resized_image)\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    final_data = dict()\n",
    "    # Load in json file to create dictionary: key = class label; value = file path\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    for label in class_label:\n",
    "        final_data.update({label : data.get(label)})\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started off with loading data from **train.json** into `dictionary{label:[image_dir]`. We will use (Histogram of Oriented Gradient (HOG))[https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog] of every image flatten into 1-D array and form a new return data as `dictionary{label: [image_name,[hog_array]]}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_processing(data, label_dictionary):\n",
    "    final_label = []\n",
    "    for i in label_dictionary.keys():\n",
    "        label_value = label_dictionary.get(i)\n",
    "        for image in data.get(i):\n",
    "            final_label.append(label_value)\n",
    "    return np.array(final_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HOG_data(data):\n",
    "    feature_lists = []\n",
    "    for image in data:\n",
    "            file_name = image.split('/')[1]\n",
    "            file_image = get_image(parent_dir + \"images/\" + image)\n",
    "            # given 32x32 cell\n",
    "            image_feature, image_hog = hog(file_image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(8, 8), block_norm = 'L2-Hys', visualize=True, multichannel=True)\n",
    "            feature_lists.append(image_feature)\n",
    "    return np.array(feature_lists)\n",
    "\n",
    "def feature_format(data):\n",
    "    feature_matrix = load_HOG_data(data)\n",
    "    ss = StandardScaler()\n",
    "    food_stand = ss.fit_transform(feature_matrix)\n",
    "    pca = PCA(n_components = feature_matrix.shape[0])\n",
    "    food_pca = ss.fit_transform(food_stand)\n",
    "    return food_pca\n",
    "\n",
    "def pre_process_data(data_json):\n",
    "    pca_data = dict()\n",
    "    labels = list(data_json.keys())\n",
    "    for label in labels:\n",
    "        pca_data.update({label : feature_format(data_json.get(label))})\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataset(train_json):\n",
    "    # Getting all the label and combination of all label\n",
    "    labels = list(train_json.keys())\n",
    "    class_combinations = list(combinations(labels, 2))\n",
    "\n",
    "    #Get all pca dictinary data for both train and test\n",
    "    train_pca_dict = pre_process_data(train_json)\n",
    "    for combination in class_combinations:\n",
    "        #SVM classification\n",
    "        svm = SVC(gamma='auto', kernel='linear', probability=True)\n",
    "        combine_train_data = np.vstack((train_pca_dict.get(combination[0]), train_pca_dict.get(combination[1])))\n",
    "        label_dict = {combination[0] : 1, combination[1] : -1}\n",
    "        label_lists_train = label_processing(train_json, label_dict)\n",
    "\n",
    "        x_train = pd.DataFrame(combine_train_data)\n",
    "        y_train = pd.Series(label_lists_train)\n",
    "\n",
    "        svm.fit(x_train, y_train)\n",
    "        filename = combination[0] + \"_\" + combination[1] + \"_model.sav\"\n",
    "        model_filename = model_dir + \"/models_save/\" + filename\n",
    "        pickle.dump(svm, open(model_filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
