{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install these library on TERMINAL if you haven't install\n",
    "\n",
    "pip install matplotlib tensorflow opency-python scikit-learn scikit-image pillow pandas\n",
    "\n",
    "\n",
    "For Window Linux Subsystem user:\n",
    "1. Display plot from matplotlib require Xming Server running.\n",
    "2. Download (Xming)[https://sourceforge.net/projects/xming/]\n",
    "3. Update .bashrc\n",
    "    vim ~/.bashrc\n",
    "4. Append at the end of the file\n",
    "    export DISPLAY=:0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'libsvm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-240f1d263ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Library for LIBSVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvmutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libsvm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.filters import prewitt_h,prewitt_v, sobel\n",
    "from skimage.data import camera\n",
    "\n",
    "from itertools import combinations\n",
    "# Libs for Scikit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# Libs for LIBSVM\n",
    "from libsvm.svmutil import *\n",
    "# libs for tf and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for tkinter\n",
    "# This block DOES NOT need to run on jupyter\n",
    "if os.environ.get('DISPLAY','') == '':\n",
    "    print('no display found. Using non-interactive Agg backend')\n",
    "    mpl.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "# parent_dir and model_dir should be change according \n",
    "# the dataset location and location of save models according to users \n",
    "# 101 is main dataset, 102 is for testing with smaller dataset\n",
    "parent_dir = \"/mnt/c/Users/nhmin/Downloads/food-101/\"\n",
    "bin_n = 16 # Number of bin\n",
    "project_dir = os.getcwd()\n",
    "model_dir = \"/mnt/c/Users/nhmin/Downloads/\"\n",
    "class_label = {\"pad_thai\" : 0, \"pho\" : 1, \"ramen\" : 2, \"spaghetti_bolognese\" : 3, \"spaghetti_carbonara\" : 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_image()` taken in image path and return numpy 384x384 array of the image.\n",
    "`load_json(path)` return a dictionary of classes as key and list of image directories as value. This is load from **train.json** and **test.json** in the **meta** folder from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return np img size 227x227\n",
    "def get_image(path):\n",
    "    # image resize to 227x227\n",
    "    img = Image.open(path + \".jpg\")\n",
    "    resized_image = img.resize((227,227), Image.ANTIALIAS)\n",
    "    return np.array(resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    final_data = dict()\n",
    "    # Load in json file to create dictionary: key = class label; value = file path\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Only get information from needed class\n",
    "    for label in class_label:\n",
    "        final_data.update({label : data.get(label)})\n",
    "    return final_data\n",
    "\n",
    "#=========================\n",
    "# Exclusive block for showing a sample of how json load data\n",
    "data_head = 5\n",
    "sample_data = load_json(parent_dir + \"/meta/test.json\")\n",
    "for key, value in sample_data:\n",
    "    print(key)\n",
    "    print(value[i] for i in range(0,data_head))\n",
    "    for i in range(0, data_head):\n",
    "        print(value[i])   \n",
    "#=========================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started off with loading data from **train.json** into `dictionary{label:[image_dir]`. We will use (Histogram of Oriented Gradient (HOG))[https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog] of every image flatten into 1-D array and form a new return data as `dictionary{label: [image_name,[hog_array]]}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_processing(data, label_dictionary):\n",
    "    final_label = []\n",
    "    for i in label_dictionary.keys():\n",
    "        label_value = label_dictionary.get(i)\n",
    "        for image in data.get(i):\n",
    "            final_label.append(label_value)\n",
    "    return np.array(final_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HOG_data(data):\n",
    "    feature_lists = []\n",
    "    for image in data:\n",
    "            file_name = image.split('/')[1]\n",
    "            file_image = get_image(parent_dir + \"images/\" + image)\n",
    "            # given 32x32 cell\n",
    "            image_feature, image_hog = hog(file_image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(8, 8), block_norm = 'L2-Hys', visualize=True, multichannel=True)\n",
    "            feature_lists.append(image_feature)\n",
    "    return np.array(feature_lists)\n",
    "\n",
    "def feature_format(data):\n",
    "    feature_matrix = load_HOG_data(data)\n",
    "    ss = StandardScaler()\n",
    "    food_stand = ss.fit_transform(feature_matrix)\n",
    "    pca = PCA(n_components = feature_matrix.shape[0])\n",
    "    food_pca = ss.fit_transform(food_stand)\n",
    "    return food_pca\n",
    "\n",
    "def pre_process_data(data_json):\n",
    "    pca_data = dict()\n",
    "    labels = list(data_json.keys())\n",
    "    for label in labels:\n",
    "        pca_data.update({label : feature_format(data_json.get(label))})\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataset(train_json):\n",
    "    # Getting all the label and combination of all label\n",
    "    labels = list(train_json.keys())\n",
    "    class_combinations = list(combinations(labels, 2))\n",
    "\n",
    "    #Get all pca dictinary data for both train and test\n",
    "    train_pca_dict = pre_process_data(train_json)\n",
    "    for combination in class_combinations:\n",
    "        #SVM classification\n",
    "        svm = SVC(gamma='auto', kernel='linear', probability=True)\n",
    "        combine_train_data = np.vstack((train_pca_dict.get(combination[0]), train_pca_dict.get(combination[1])))\n",
    "        label_dict = {combination[0] : 1, combination[1] : -1}\n",
    "        label_lists_train = label_processing(train_json, label_dict)\n",
    "\n",
    "        x_train = pd.DataFrame(combine_train_data)\n",
    "        y_train = pd.Series(label_lists_train)\n",
    "\n",
    "        svm.fit(x_train, y_train)\n",
    "        filename = combination[0] + \"_\" + combination[1] + \"_model.sav\"\n",
    "        model_filename = model_dir + \"/models_save/\" + filename\n",
    "        pickle.dump(svm, open(model_filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
